{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nparslow/disfluency_gen/blob/develop/docs/tutorials/nmt_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tnxXKDjq3jEL",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# refactored from:\n",
    "#https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/nmt_with_attention.ipynb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "repoRoot = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(os.path.join(repoRoot, \"src\", \"disfluency_generator\"))\n",
    "\n",
    "import tensorflow as tf\n",
    "from machine_translator import load_data, create_dataset, print_examples, tf_lower_and_split_punct,\\\n",
    "    create_text_processor\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from trainTranslator import TrainTranslator, BatchLogs\n",
    "from maskedLoss import MaskedLoss\n",
    "\n",
    "from translator import Translator\n",
    "from trainTranslator import TrainTranslator\n",
    "\n",
    "import pathlib\n",
    "\n",
    "from letsread_prepare_translations import LetsReadDataPrep\n",
    "from portuguese_phoneme_to_grapheme import PhonemeToGrapheme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRVATYOgJs1b",
    "outputId": "0d4f0d79-6557-4c52-cb30-19c63d031a35",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot parse t6j~ at ~\n",
      "Cannot parse lun6w at w\n",
      "Cannot parse fi...ka...@ju at ju\n",
      "Cannot parse kumunica at ca\n",
      "Cannot parse gOc6~w~ at c6~w~\n",
      "Cannot parse tevulz6w~ at w~\n",
      "Cannot parse sÂj~ at Âj~\n",
      "Cannot parse k6ir6w~ at w~\n",
      "Cannot parse mej at j\n",
      "Last example of data:\n",
      "flole mocla ambife dantrar mever\n",
      "flole mocla ambife dantrar e mever\n",
      "tf.Tensor(\n",
      "[b'Os seus ombros estavam cobertos por um manto verde e o seu vestido era da cor da chama viva.'\n",
      " b'O Sol \\xc3\\xa9 uma enorme bola de g\\xc3\\xa1s quente, que se formou a partir de uma nuvem de g\\xc3\\xa1s e de p\\xc3\\xb3 que flutuava no espa\\xc3\\xa7o.'\n",
      " b'Quando eu era nova tinha namorados que me diziam que eu era linda e me atiravam cravos quando eu passava.'\n",
      " b'Falaram de vento, chuva, frio, enfim, s\\xc3\\xb3 de coisas desagrad\\xc3\\xa1veis.'\n",
      " b'A Ester apaga as sete velas.'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b'os seus ombros estavam cobertos por um manto verde e o seu vestido era de core da chama viva'\n",
      " b'o sol \\xc3\\xa9 uma enorme bola de g\\xc3\\xa1s quente que se forme formou a partir de uma nuvem de g\\xc3\\xa1s de e de p\\xc3\\xb3 que flutua no espa\\xc3\\xa7o'\n",
      " b'quando eu era nova tinha namorados que me diziam que eu era linda e me e me atirava cravos quando eu passava'\n",
      " b'falaram de vento chuva frio enfim s\\xc3\\xb3 de coisas dezagravdaveis'\n",
      " b'ae istera apaga a as sete velas'], shape=(5,), dtype=string)\n",
      "First 10 words of input vocab:\n",
      "['', '[UNK]', '[START]', '[END]', '.', ',', 'a', 'e', 'o', 'de']\n",
      "First 10 words of target vocab:\n",
      "['', '[UNK]', '[START]', '[END]', 'a', 'e', 'o', 'de', 'que', 'um']\n",
      "Example input token sequences (indices):\n",
      "tf.Tensor(\n",
      "[[   2   43   22   12 1283   10  222    9  539  101]\n",
      " [   2   76   34    5   76   34   23  932    8  127]\n",
      " [   2  556  897  103  220   10   20   41  837    4]], shape=(3, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_path = pathlib.Path(repoRoot, \"data\")\n",
    "verbose = 1\n",
    "#------------------\n",
    "letsread_corpus_path = os.path.join(data_path, \"LetsReadDB\")\n",
    "\n",
    "p2g = PhonemeToGrapheme(os.path.join(repoRoot, \"resources\", \"sampa.tsv\"))\n",
    "inputs, targets = LetsReadDataPrep(letsread_corpus_path, p2g).prep_letsread()\n",
    "\n",
    "if verbose > 0:\n",
    "    print(f\"Last example of data:\\n{inputs[-1]}\\n{targets[-1]}\")\n",
    "\n",
    "# we'll leave off the first 20 as a test set (todo improve)\n",
    "dataset = create_dataset(inputs[20:], targets[20:], BATCH_SIZE=64)\n",
    "\n",
    "if verbose > 0:\n",
    "    print(\"Printing Examples (before normalisation):\")\n",
    "    print_examples(dataset)\n",
    "\n",
    "# todo - check with corpus:\n",
    "max_vocab_size = 5000\n",
    "\n",
    "input_text_processor = create_text_processor(inputs, max_vocab_size)\n",
    "\n",
    "if verbose > 0:\n",
    "    # todo better checking:\n",
    "    print(\"First 10 words of input vocab:\")\n",
    "    print(input_text_processor.get_vocabulary()[:10])\n",
    "\n",
    "# note - we don't have to have the same output vocab size:\n",
    "output_text_processor = create_text_processor(targets, max_vocab_size)\n",
    "\n",
    "if verbose > 0:\n",
    "    print(\"First 10 words of target vocab:\")\n",
    "    print(output_text_processor.get_vocabulary()[:10])\n",
    "\n",
    "if verbose > 0:\n",
    "    for example_input_batch, example_target_batch in dataset.take(1):\n",
    "        print(\"Example input token sequences (indices):\")\n",
    "        example_tokens = input_text_processor(example_input_batch)\n",
    "        print(example_tokens[:3, :10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzQWx2saImMV"
   },
   "source": [
    "Before getting into it define a few constants for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_a9uNz3-IrF-"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aI02XFjoEt1k"
   },
   "source": [
    "Now that you're confident that the training step is working, build a fresh copy of the model to train from scratch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpObfY22IddU"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "While there's nothing wrong with writing your own custom training loop, implementing the `Model.train_step` method, as in the previous section, allows you to run `Model.fit` and avoid rewriting all that boiler-plate code. \n",
    "\n",
    "This tutorial only trains for a couple of epochs, so use a `callbacks.Callback` to collect the history of batch losses, for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J7m4mtnj80sq"
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_loss = BatchLogs('batch_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor)\n",
    "\n",
    "# Configure the loss and optimizer\n",
    "train_translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQd_esVVoSf3",
    "outputId": "2536bbf4-078b-4f12-b0ac-c3d59ef81dfc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "36/36 [==============================] - 92s 3s/step - batch_loss: 6.5415\n",
      "Epoch 2/3\n",
      "36/36 [==============================] - 96s 3s/step - batch_loss: 5.7733\n",
      "Epoch 3/3\n",
      "36/36 [==============================] - 103s 3s/step - batch_loss: 5.2683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ae56bf130>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_translator.fit(dataset, epochs=3,\n",
    "                     callbacks=[batch_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "38rLdlmtQHCm",
    "outputId": "efbeff93-c194-42ce-e124-36a36f88c350"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'CE/token')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS/ElEQVR4nO3df7DldV3H8edLdpEfKquyIS0LS7oTgxi/7iBKPxCzgEgytcExJdO2TEcp+6E2o+kfllNpmY62CQoOmQVoq2ENIWk1Cd7dll+LP1bNWAZlBdyFJHDp3R/nu3m8e+7ew+79nuu9n+dj5sz9/vic73l/57N7X/f763NSVUiS2vWohS5AkrSwDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMb1FgRJDkpyQ5Ibk9ya5C0j2jw6yUeSbE1yfZI1fdUjSRqtzyOCB4GzqupE4CTg7CSnz2jzcuDeqnoK8E7g7T3WI0kaobcgqIH7u9nl3Wvm02vnA5d201cAz06SvmqSJO1pWZ8bT3IAsBF4CvCeqrp+RpNVwO0AVbUryQ7gicA3Z2xnHbAO4NBDDz31uOOO67NsSVpyNm7c+M2qWjlqXa9BUFUPAyclWQF8NMkJVXXLPmxnPbAeYGpqqqanp+e3UEla4pJ8bbZ1E7lrqKq+BVwHnD1j1R3AaoAky4DDgLsnUZMkaaDPu4ZWdkcCJDkYeA7w+RnNNgAXdtMvAD5VjoInSRPV56mhI4FLu+sEjwL+pqo+keStwHRVbQAuBj6UZCtwD3BBj/VIkkboLQiq6ibg5BHL3zQ0/T/AC/uqQZI0N58slqTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIa11sQJFmd5LokW5LcmuS1I9qcmWRHks3d60191SNJGm1Zj9veBbyuqjYleSywMck1VbVlRrt/qarzeqxDkrQXvR0RVNWdVbWpm74PuA1Y1dfnSZL2zUSuESRZA5wMXD9i9TOS3Jjkk0meOol6JEnf1eepIQCSPAa4ErioqnbOWL0JOKaq7k9yLvAxYO2IbawD1gEcffTR/RYsSY3p9YggyXIGIXB5VV01c31V7ayq+7vpq4HlSQ4f0W59VU1V1dTKlSv7LFmSmtPnXUMBLgZuq6p3zNLmSV07kpzW1XN3XzVJkvbU56mhM4CXADcn2dwteyNwNEBVvQ94AfDKJLuAB4ALqqp6rEmSNENvQVBV/wpkjjbvBt7dVw2SpLn5ZLEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIa11sQJFmd5LokW5LcmuS1I9okybuSbE1yU5JT+qpHkjTash63vQt4XVVtSvJYYGOSa6pqy1Cbc4C13evpwHu7n5KkCentiKCq7qyqTd30fcBtwKoZzc4HLquBzwIrkhzZV02SpD1N5BpBkjXAycD1M1atAm4fmt/GnmFBknVJppNMb9++vbc6JalFvQdBkscAVwIXVdXOfdlGVa2vqqmqmlq5cuX8FihJjes1CJIsZxACl1fVVSOa3AGsHpo/qlsmSZqQPu8aCnAxcFtVvWOWZhuAl3Z3D50O7KiqO/uqSZK0pz7vGjoDeAlwc5LN3bI3AkcDVNX7gKuBc4GtwLeBl/VYjyRphN6CoKr+FcgcbQp4VV81SJLm5pPFktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS48YeayjJM4E1w++pqst6qEmSNEFjBUGSDwFPBjYDD3eLCzAIJGmRG/eIYAo4vhstVJK0hIx7jeAW4El9FiJJWhjjHhEcDmxJcgPw4O6FVfXcXqqSJE3MuEHw+30WIUlaOGMFQVV9OskxwNqq+qckhwAH9FuaJGkSxrpGkORXgCuAv+gWrQI+1lNNkqQJGvdi8asYfBn9ToCq+hLwA30VJUmanHGD4MGqemj3TJJlDJ4jkCQtcuMGwaeTvBE4OMlzgL8FPt5fWZKkSRk3CF4PbAduBn4VuLqqfq+3qiRJEzP27aNV9SbgLwGSHJDk8qp6cX+lSZImYdwjgtVJ3gCQ5EDgSuBLvVUlSZqYcYPgl4GndWHwCeDTVfX7vVUlSZqYvZ4aSnLK0OyfMXiO4N8YXDw+pao29VmcJKl/c10j+JMZ8/cCx3fLCzhrtjcmuQQ4D7irqk4Ysf5M4O+Ar3aLrqqqt45VtSRp3uw1CKrqWfux7Q8C72bv31nwL1V13n58hiRpP407xMRhSd6RZLp7/UmSw/b2nqr6DHDPvFQpSerNuBeLLwHuA36he+0EPjAPn/+MJDcm+WSSp87WKMm63SG0ffv2efhYSdJu4z5H8OSqev7Q/FuSbN7Pz94EHFNV9yc5l8EgdmtHNayq9cB6gKmpKYe2kKR5NO4RwQNJfnT3TJIzgAf254OramdV3d9NXw0sT3L4/mxTkvTIjXtE8GvAZUPXBe4FLtyfD07yJOAbVVVJTmMQSnfvzzYlSY/cuEGws6pOTPI4GPw1n+TYvb0hyYeBM4HDk2wD3gws797/PuAFwCuT7GJwdHFBVXnaR5ImbNwguBI4pap2Di27Ajh1tjdU1Yv2tsGqejeD20slSQtorieLjwOeChyW5OeHVj0OOKjPwiRJkzHXEcEPM3g6eAXws0PL7wN+paeaJEkTNFcQHAL8FrC+qv59AvVIkiZsriA4msG3kS1Pci3wSeAGL+pK0tKx1+cIqurtVXUWcC5wI4PhqDcl+askL01yxCSKlCT1Z6y7hqrqPuCj3YskxwPnMBhQ7qd7q06S1Lu9HhEk+cWh6TN2T1fVFuDBqjIEJGmRm2uIid8cmv7zGet+eZ5rkSQtgLmCILNMj5qXJC1CcwVBzTI9al6StAjNdbH4uCQ3Mfjr/8ndNN38D/VamSRpIuYKghOBI4DbZyxfDXy9l4okSRM116mhdwI7quprwy9gR7dOkrTIzRUER1TVzTMXdsvW9FKRJGmi5gqCFXtZd/A81iFJWiBzBcF0kj1GGU3yCmBjPyVJkiZprovFFwEfTfJivvuLfwo4EHhej3VJkiZkr0FQVd8AnpnkWcAJ3eK/r6pP9V6ZJGkixh107jrgup5rkSQtgLmuEUiSljiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxvUWBEkuSXJXkltmWZ8k70qyNclNSU7pqxZJ0uz6PCL4IHD2XtafA6ztXuuA9/ZYiyRpFr0FQVV9BrhnL03OBy6rgc8CK5Ic2Vc9kqTRFvIawSq+9yswt3XL9pBkXZLpJNPbt2+fSHGS1IpFcbG4qtZX1VRVTa1cuXKhy5GkJWUhg+AOYPXQ/FHdMknSBC1kEGwAXtrdPXQ6sKOq7lzAeiSpSWN9H8G+SPJh4Ezg8CTbgDcDywGq6n3A1cC5wFbg28DL+qpFkjS73oKgql40x/oCXtXX50uSxrMoLhZLkvpjEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWpcr0GQ5OwkX0iyNcnrR6z/pSTbk2zuXq/osx5J0p6W9bXhJAcA7wGeA2wDPpdkQ1VtmdH0I1X16r7qkCTtXZ9HBKcBW6vqK1X1EPDXwPk9fp4kaR/0GQSrgNuH5rd1y2Z6fpKbklyRZHWP9UiSRljoi8UfB9ZU1Y8A1wCXjmqUZF2S6STT27dvn2iBkrTU9RkEdwDDf+Ef1S37f1V1d1U92M2+Hzh11Iaqan1VTVXV1MqVK3spVpJa1WcQfA5Ym+TYJAcCFwAbhhskOXJo9rnAbT3WI0kaobe7hqpqV5JXA/8IHABcUlW3JnkrMF1VG4DXJHkusAu4B/ilvuqRJI2WqlroGh6Rqampmp6eXugyJGlRSbKxqqZGrVvoi8WSpAVmEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjes1CJKcneQLSbYmef2I9Y9O8pFu/fVJ1vRZjyRpT70FQZIDgPcA5wDHAy9KcvyMZi8H7q2qpwDvBN7eVz2SpNH6PCI4DdhaVV+pqoeAvwbOn9HmfODSbvoK4NlJ0mNNkqQZlvW47VXA7UPz24Cnz9amqnYl2QE8EfjmcKMk64B13ez9Sb6wjzUdPnPbS5D7uDS4j0vD99M+HjPbij6DYN5U1Xpg/f5uJ8l0VU3NQ0nft9zHpcF9XBoWyz72eWroDmD10PxR3bKRbZIsAw4D7u6xJknSDH0GweeAtUmOTXIgcAGwYUabDcCF3fQLgE9VVfVYkyRpht5ODXXn/F8N/CNwAHBJVd2a5K3AdFVtAC4GPpRkK3APg7Do036fXloE3MelwX1cGhbFPsY/wCWpbT5ZLEmNMwgkqXHNBMFcw10sRklWJ7kuyZYktyZ5bbf8CUmuSfKl7ufjF7rW/ZHkgCT/keQT3fyx3ZAkW7shSg5c6Br3V5IVSa5I8vkktyV5xlLqxyS/0f0bvSXJh5MctBT6McklSe5KcsvQspH9loF3dft7U5JTFq7y79VEEIw53MVitAt4XVUdD5wOvKrbr9cD11bVWuDabn4xey1w29D824F3dkOT3MtgqJLF7s+Af6iq44ATGezvkujHJKuA1wBTVXUCg5tHLmBp9OMHgbNnLJut384B1navdcB7J1TjnJoIAsYb7mLRqao7q2pTN30fg18eq/jeoTsuBX5uQQqcB0mOAn4GeH83H+AsBkOSwCLfP4AkhwE/zuAuOqrqoar6FkuoHxncoXhw97zQIcCdLIF+rKrPMLjjcdhs/XY+cFkNfBZYkeTIiRQ6h1aCYNRwF6sWqJZedCO3ngxcDxxRVXd2q74OHLFQdc2DPwV+B/jfbv6JwLeqalc3vxT68lhgO/CB7hTY+5McyhLpx6q6A/hj4L8YBMAOYCNLrx93m63fvm9/D7USBEtakscAVwIXVdXO4XXdA3qL8h7hJOcBd1XVxoWupWfLgFOA91bVycB/M+M00CLvx8cz+Gv4WOAHgUPZ83TKkrRY+q2VIBhnuItFKclyBiFweVVd1S3+xu5Dzu7nXQtV3346A3hukv9kcDrvLAbn0ld0pxhgafTlNmBbVV3fzV/BIBiWSj/+JPDVqtpeVd8BrmLQt0utH3ebrd++b38PtRIE4wx3seh058svBm6rqncMrRoeuuNC4O8mXdt8qKo3VNVRVbWGQZ99qqpeDFzHYEgSWMT7t1tVfR24PckPd4ueDWxhifQjg1NCpyc5pPs3u3v/llQ/Dpmt3zYAL+3uHjod2DF0CmlhVVUTL+Bc4IvAl4HfW+h65mmffpTBYedNwObudS6D8+jXAl8C/gl4wkLXOg/7eibwiW76h4AbgK3A3wKPXuj65mH/TgKmu778GPD4pdSPwFuAzwO3AB8CHr0U+hH4MIPrHt9hcGT38tn6DQiDuxe/DNzM4C6qBd+HqnKICUlqXSunhiRJszAIJKlxBoEkNc4gkKTGGQSS1DiDQE1L8nCSzUluTLIpyTPnaL8iya+Psd1/TjL2l5Z3I3Iem+SiJC8a933SfDAI1LoHquqkqjoReAPwB3O0XwHMGQT7YE1VfRX4CeAzPWxfmpVBIH3X4xgMh0ySxyS5tjtKuDnJ7tFq/xB4cncU8Udd29/t2tyY5A+HtvfCJDck+WKSHxv1gUkuT7IFOC7JZuCngL9P8oq+dlKaqbcvr5cWiYO7X8AHAUcyGM8I4H+A51XVziSHA59NsoHBYHAnVNVJAEnOYTCg2tOr6ttJnjC07WVVdVqSc4E3Mxhz53tU1YuTvBA4msEYQ39cVS/sY0el2RgEat0DQ7/UnwFcluQEBsMBvC3JjzMYAnsVo4eB/kngA1X1bYCqGh6bfvcggBuBNXup4RQGQxL8CHDjPu+JtI8MAqlTVf/e/fW/ksGYTSuBU6vqO90IqAc9wk0+2P18mBH/17ojhbcxGJ75vO7z/jvJs6vqWfu2F9Ij5zUCqZPkOAZfo3g3cBiD70L4TpJnAcd0ze4DHjv0tmuAlyU5pNvG8Kmhvaqqq4FTgVuq6mnArcDJhoAmzSMCtW73NQIYnA66sKoeTnI58PEkNzMYFfTzAFV1d5J/676s/JNV9dtJTgKmkzwEXA288RF8/snAjd3w6MtrxhcLSZPg6KOS1DhPDUlS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1Lj/A0E5FHtXDvTpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(batch_loss.logs)\n",
    "plt.ylim([0, 3])\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('CE/token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iBQzFZ9uWU79"
   },
   "outputs": [],
   "source": [
    "translator = Translator(\n",
    "    encoder=train_translator.encoder,\n",
    "    decoder=train_translator.decoder,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyvxT5V0_X5B",
    "outputId": "039a2eea-9600-4df8-f83f-f89cba5f2f3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, decoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn, embedding_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: portugues_trial_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: portugues_trial_1/assets\n"
     ]
    }
   ],
   "source": [
    "model_name = 'portugues_trial_1'\n",
    "tf.saved_model.save(translator, model_name,\n",
    "                    signatures={'serving_default': translator.tf_translate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-I0j3i3ekOba"
   },
   "outputs": [],
   "source": [
    "#model_name = \n",
    "reloaded = tf.saved_model.load(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXZF__FZXJCm",
    "outputId": "380eaf26-17ba-4dcd-8261-ed6e5da6e3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O carro do meu tio é azul.\n",
      "ela para o mustra o branco havia\n",
      "------------\n",
      "Era uma vez um elefante muito pequenino e muito enfezado.\n",
      "os burro uma fila caim todo uma encostada apareceu o teve ja palacio que o ce mas uma cravalos saboroso\n",
      "------------\n",
      "Desta vez contou com uma voz mais alegre e um aperto no coração.\n",
      "um fiz e de seguinte que primeira culera\n",
      "------------\n",
      "Ontem a Joaninha fez um lindo desenho.\n",
      "quero parece ana gostava poeirinha\n",
      "------------\n",
      "O vento amainou.\n",
      "o belo gelo cimco ausencia\n",
      "------------\n",
      "Era uma bela casa.\n",
      "uma esperteza ja e o cedo que os padrinhos as vezinho e os osso\n",
      "------------\n",
      "Parecia que toda a sabedoria da terra estava reunida naquela sala.\n",
      "a mara essa falanos\n",
      "------------\n",
      "Os Maias vieram habitar uma casa em Lisboa no Outono de mil oitocentos e setenta e cinco.\n",
      "jame peiza a caule havia de tecnologia\n",
      "------------\n",
      "Quem quer casar com a Carochinha, que é formosa e bonitinha?\n",
      "que aquela degelo aprezemtoce reservara\n",
      "------------\n",
      "Parecia que as ondas iam cercar a casa e que o mar ia devorar o mundo.\n",
      "vaidosa dava ro rato ativada a ca um sobre na ruiva pedro e o ninguem que era de arve\n",
      "------------\n",
      "A notícia desta viagem causou grande espanto.\n",
      "o fora eu mocho muito belo copa\n",
      "------------\n",
      "A Zélia jogou e meteu um belo golo na baliza.\n",
      "diz no mae lagartos do pa pareca\n",
      "------------\n",
      "A mãe do Flávio era florista.\n",
      "o rapaz foi estava falare de cobrecaltado popo\n",
      "------------\n",
      "Vendia lindos gladíolos e glicínias.\n",
      "busos alexandre fi feitas culanhei havia para abriu principe semanas\n",
      "------------\n",
      "A Catarina e a Mira estão distraídas.\n",
      "atiraram entrar uma ruido foi uma chocar e correr\n",
      "------------\n",
      "Quero eu, quero eu! Sou muito comilão, mas também dizem que sou bonacheirão.\n",
      "a cusceio agua da ramalete com animais coise em rouba e desenho\n",
      "------------\n",
      "És muito simpático e pareces ser divertido.\n",
      "comecou eu delmeus caltapucinhas gelado\n",
      "------------\n",
      "Mas com essa voz, acordavas-me a mim e aos meninos de noite!\n",
      "mas caranguejos contava a a bruxa festa\n",
      "------------\n",
      "Quase enraivecida, a cegonha largou a falar como uma matraca.\n",
      "a vale bocam boca a arcitectura\n",
      "------------\n",
      "Ficaram a conversar na varanda.\n",
      "a galo batalha a neta o ireivecida com com cafe a nascenca a galinha\n",
      "------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "#three_input_text = tf.constant([\n",
    "#    # This is my life.\n",
    "#    'Esta es mi vida.',\n",
    "#    # Are they still home?\n",
    "#    '¿Todavía están en casa?',\n",
    "#    # Try to find out.'\n",
    "#    'Tratar de descubrir.',\n",
    "#])\n",
    "test_sentences = tf.constant(inputs[:20])  #targets[20:]\n",
    "\n",
    "result = reloaded.tf_translate(test_sentences)\n",
    "\n",
    "for orig, tr in zip(test_sentences, result['text']):\n",
    "    print(orig.numpy().decode())\n",
    "    print(tr.numpy().decode())\n",
    "    print(\"------------\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "nmt_with_attention.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
