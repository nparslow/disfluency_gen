{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nparslow/disfluency_gen/blob/develop/docs/tutorials/nmt_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tnxXKDjq3jEL",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the GPU is accessible:\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# refactored and adapted from:\n",
    "#https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/nmt_with_attention.ipynb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "repoRoot = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# for local running without installing the package:\n",
    "sys.path.append(os.path.join(repoRoot, \"src\"))\n",
    "\n",
    "import tensorflow as tf\n",
    "from disfluency_generator.data_preparation import load_data, create_dataset, print_examples, \\\n",
    "     tf_lower_and_split_punct, create_text_processor\n",
    "from disfluency_generator.encoder import Encoder\n",
    "from disfluency_generator.decoder import Decoder\n",
    "from disfluency_generator.trainTranslator import TrainTranslator, BatchLogs\n",
    "from disfluency_generator.maskedLoss import MaskedLoss\n",
    "from disfluency_generator.translator import Translator\n",
    "from disfluency_generator.trainTranslator import TrainTranslator\n",
    "\n",
    "import pathlib\n",
    "\n",
    "from disfluency_generator.letsread_prepare_translations import LetsReadDataPrep\n",
    "from disfluency_generator.portuguese_phoneme_to_grapheme import PhonemeToGrapheme\n",
    "\n",
    "print(\"Checking the GPU is accessible:\")\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRVATYOgJs1b",
    "outputId": "0d4f0d79-6557-4c52-cb30-19c63d031a35",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot parse t6j~ at ~\n",
      "Cannot parse lun6w at w\n",
      "Cannot parse fi...ka...@ju at ju\n",
      "Cannot parse kumunica at ca\n",
      "Cannot parse gOc6~w~ at c6~w~\n",
      "Cannot parse tevulz6w~ at w~\n",
      "Cannot parse sÂj~ at Âj~\n",
      "Likely typo: [l\"a:du\n",
      "Likely typo: [i~v@rn\"ar\n",
      "Cannot parse k6ir6w~ at w~\n",
      "Last example of data:\n",
      "flole mocla ambife dantrar mever\n",
      "flole mocla ambife dantrar e mever\n",
      "\n",
      "Printing Examples (before normalisation):\n",
      "Quis seguir viagem, mas estava tão fraco, magro e pálido, que eles não o deixaram partir.\n",
      "quis seguir viagem mas estava tão fraco magro e a pal e pálido que que eles não o deixaram partir\n",
      "--------------------\n",
      "Diz a cabra que estava na vinha, que está pronta para ser a madrinha.\n",
      "diz a cabra que estava ai que estava na vinha que estaa pronta para ser a madrinha\n",
      "--------------------\n",
      "Na noite de Natal, em frente da enorme lareira, havia uma mesa muito comprida.\n",
      "na noite *DEL(de) natal em frente da enorme lareira havia uma mesa muito comprida\n",
      "--------------------\n",
      "Como teria acontecido?\n",
      "como teria acontecido\n",
      "--------------------\n",
      "Era uma vez um gato maltez.\n",
      "era uma vez um gato maltez\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_path = pathlib.Path(repoRoot, \"data\")\n",
    "verbose = 1\n",
    "#------------------\n",
    "letsread_corpus_path = os.path.join(data_path, \"LetsReadDB\")\n",
    "\n",
    "p2g = PhonemeToGrapheme(os.path.join(repoRoot, \"resources\", \"sampa.tsv\"))\n",
    "data_prep = LetsReadDataPrep(letsread_corpus_path, p2g)\n",
    "inputs, targets = data_prep.prep_letsread()\n",
    "\n",
    "\n",
    "if verbose > 0:\n",
    "    print(f\"Last example of data:\\n{inputs[-1]}\\n{targets[-1]}\")\n",
    "\n",
    "# we'll leave off the first 20 as a test set (todo improve)\n",
    "dataset = create_dataset(inputs[20:], targets[20:], BATCH_SIZE=64//2)\n",
    "\n",
    "if verbose > 0:\n",
    "    print(\"\")\n",
    "    print(\"Printing Examples (before normalisation):\")\n",
    "    print_examples(dataset, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 words of input vocab:\n",
      "['', '[UNK]', '[START]', '[END]', 'a', 'e', 'o', 'de', 'que', 'um']\n",
      "First 10 words of target vocab:\n",
      "['', '[UNK]', '[START]', '[END]', 'a', 'e', 'o', 'de', 'que', 'um']\n",
      "Example input token sequences (indices):\n",
      "tf.Tensor(\n",
      "[[   2  645 1731    7    9  239    3    0    0    0]\n",
      " [   2   30  169  351 2542    3    0    0    0    0]\n",
      " [   2    6  776   15  613    5   41   22  707    5]], shape=(3, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# todo - check with corpus:\n",
    "max_vocab_size = 2917\n",
    "\n",
    "input_text_processor = create_text_processor(inputs, max_vocab_size)\n",
    "\n",
    "if verbose > 0:\n",
    "    # todo better checking:\n",
    "    print(\"First 10 words of input vocab:\")\n",
    "    print(input_text_processor.get_vocabulary()[:10])\n",
    "\n",
    "# note - we don't have to have the same output vocab size:\n",
    "output_text_processor = create_text_processor(targets, max_vocab_size)\n",
    "\n",
    "if verbose > 0:\n",
    "    print(\"First 10 words of target vocab:\")\n",
    "    print(output_text_processor.get_vocabulary()[:10])\n",
    "\n",
    "if verbose > 0:\n",
    "    for example_input_batch, example_target_batch in dataset.take(1):\n",
    "        print(\"Example input token sequences (indices):\")\n",
    "        example_tokens = input_text_processor(example_input_batch)\n",
    "        print(example_tokens[:3, :10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzQWx2saImMV"
   },
   "source": [
    "Before getting into it define a few constants for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_a9uNz3-IrF-"
   },
   "outputs": [],
   "source": [
    "# The original model was built on more data, we shrink things down for the letsread corpus \n",
    "embedding_dim = 256//2\n",
    "units = 1024//2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpObfY22IddU"
   },
   "source": [
    "### Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "J7m4mtnj80sq"
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_loss = BatchLogs('batch_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor)\n",
    "\n",
    "# Configure the loss and optimizer\n",
    "train_translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.002),  # default learning_rate = 0.001\n",
    "    loss=MaskedLoss(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate high at first:\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 30:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQd_esVVoSf3",
    "outputId": "2536bbf4-078b-4f12-b0ac-c3d59ef81dfc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "71/71 [==============================] - 27s 335ms/step - batch_loss: 5.8382\n",
      "Epoch 2/60\n",
      "71/71 [==============================] - 24s 339ms/step - batch_loss: 4.8634\n",
      "Epoch 3/60\n",
      "71/71 [==============================] - 25s 349ms/step - batch_loss: 3.8484\n",
      "Epoch 4/60\n",
      "71/71 [==============================] - 24s 342ms/step - batch_loss: 2.7246\n",
      "Epoch 5/60\n",
      "71/71 [==============================] - 24s 344ms/step - batch_loss: 1.7631\n",
      "Epoch 6/60\n",
      "71/71 [==============================] - 24s 340ms/step - batch_loss: 1.1669\n",
      "Epoch 7/60\n",
      "71/71 [==============================] - 24s 337ms/step - batch_loss: 0.8739\n",
      "Epoch 8/60\n",
      "71/71 [==============================] - 25s 348ms/step - batch_loss: 0.6955\n",
      "Epoch 9/60\n",
      "71/71 [==============================] - 26s 357ms/step - batch_loss: 0.5994\n",
      "Epoch 10/60\n",
      "71/71 [==============================] - 25s 357ms/step - batch_loss: 0.5187\n",
      "Epoch 11/60\n",
      "71/71 [==============================] - 26s 360ms/step - batch_loss: 0.4589\n",
      "Epoch 12/60\n",
      "71/71 [==============================] - 26s 367ms/step - batch_loss: 0.4396\n",
      "Epoch 13/60\n",
      "71/71 [==============================] - 25s 355ms/step - batch_loss: 0.4067\n",
      "Epoch 14/60\n",
      "71/71 [==============================] - 26s 361ms/step - batch_loss: 0.3790\n",
      "Epoch 15/60\n",
      "71/71 [==============================] - 26s 366ms/step - batch_loss: 0.3581\n",
      "Epoch 16/60\n",
      "71/71 [==============================] - 26s 362ms/step - batch_loss: 0.3454\n",
      "Epoch 17/60\n",
      "71/71 [==============================] - 26s 366ms/step - batch_loss: 0.3364\n",
      "Epoch 18/60\n",
      "71/71 [==============================] - 25s 359ms/step - batch_loss: 0.3238\n",
      "Epoch 19/60\n",
      "71/71 [==============================] - 26s 362ms/step - batch_loss: 0.3163\n",
      "Epoch 20/60\n",
      "71/71 [==============================] - 25s 356ms/step - batch_loss: 0.3175\n",
      "Epoch 21/60\n",
      "71/71 [==============================] - 25s 347ms/step - batch_loss: 0.3101\n",
      "Epoch 22/60\n",
      "71/71 [==============================] - 27s 381ms/step - batch_loss: 0.2989\n",
      "Epoch 23/60\n",
      "71/71 [==============================] - 24s 342ms/step - batch_loss: 0.2777\n",
      "Epoch 24/60\n",
      "71/71 [==============================] - 25s 349ms/step - batch_loss: 0.2685\n",
      "Epoch 25/60\n",
      "71/71 [==============================] - 25s 356ms/step - batch_loss: 0.2552\n",
      "Epoch 26/60\n",
      "71/71 [==============================] - 25s 353ms/step - batch_loss: 0.2557\n",
      "Epoch 27/60\n",
      "71/71 [==============================] - 24s 345ms/step - batch_loss: 0.2404\n",
      "Epoch 28/60\n",
      "71/71 [==============================] - 25s 346ms/step - batch_loss: 0.2325\n",
      "Epoch 29/60\n",
      "71/71 [==============================] - 24s 338ms/step - batch_loss: 0.2420\n",
      "Epoch 30/60\n",
      "71/71 [==============================] - 24s 338ms/step - batch_loss: 0.2495\n",
      "Epoch 31/60\n",
      "71/71 [==============================] - 24s 345ms/step - batch_loss: 0.2533\n",
      "Epoch 32/60\n",
      "71/71 [==============================] - 25s 354ms/step - batch_loss: 0.2190\n",
      "Epoch 33/60\n",
      "71/71 [==============================] - 24s 343ms/step - batch_loss: 0.1999\n",
      "Epoch 34/60\n",
      "71/71 [==============================] - 25s 348ms/step - batch_loss: 0.1688\n",
      "Epoch 35/60\n",
      "71/71 [==============================] - 24s 343ms/step - batch_loss: 0.1472\n",
      "Epoch 36/60\n",
      "71/71 [==============================] - 25s 355ms/step - batch_loss: 0.1319\n",
      "Epoch 37/60\n",
      "71/71 [==============================] - 24s 344ms/step - batch_loss: 0.1214\n",
      "Epoch 38/60\n",
      "71/71 [==============================] - 24s 344ms/step - batch_loss: 0.1146\n",
      "Epoch 39/60\n",
      "71/71 [==============================] - 24s 342ms/step - batch_loss: 0.1073\n",
      "Epoch 40/60\n",
      "71/71 [==============================] - 24s 339ms/step - batch_loss: 0.1008\n",
      "Epoch 41/60\n",
      "71/71 [==============================] - 24s 343ms/step - batch_loss: 0.0978\n",
      "Epoch 42/60\n",
      "71/71 [==============================] - 24s 344ms/step - batch_loss: 0.0932\n",
      "Epoch 43/60\n",
      "71/71 [==============================] - 25s 348ms/step - batch_loss: 0.0890\n",
      "Epoch 44/60\n",
      "71/71 [==============================] - 24s 341ms/step - batch_loss: 0.0854\n",
      "Epoch 45/60\n",
      "71/71 [==============================] - 24s 339ms/step - batch_loss: 0.0827\n",
      "Epoch 46/60\n",
      "71/71 [==============================] - 25s 347ms/step - batch_loss: 0.0807\n",
      "Epoch 47/60\n",
      "71/71 [==============================] - 25s 346ms/step - batch_loss: 0.0799\n",
      "Epoch 48/60\n",
      "71/71 [==============================] - 24s 342ms/step - batch_loss: 0.0785\n",
      "Epoch 49/60\n",
      "71/71 [==============================] - 24s 343ms/step - batch_loss: 0.0760\n",
      "Epoch 50/60\n",
      "71/71 [==============================] - 25s 346ms/step - batch_loss: 0.0739\n",
      "Epoch 51/60\n",
      "71/71 [==============================] - 24s 333ms/step - batch_loss: 0.0736\n",
      "Epoch 52/60\n",
      "71/71 [==============================] - 24s 340ms/step - batch_loss: 0.0713\n",
      "Epoch 53/60\n",
      "71/71 [==============================] - 25s 346ms/step - batch_loss: 0.0706\n",
      "Epoch 54/60\n",
      "71/71 [==============================] - 25s 351ms/step - batch_loss: 0.0699\n",
      "Epoch 55/60\n",
      "71/71 [==============================] - 24s 343ms/step - batch_loss: 0.0688\n",
      "Epoch 56/60\n",
      "71/71 [==============================] - 24s 342ms/step - batch_loss: 0.0685\n",
      "Epoch 57/60\n",
      "71/71 [==============================] - 25s 352ms/step - batch_loss: 0.0675\n",
      "Epoch 58/60\n",
      "71/71 [==============================] - 24s 339ms/step - batch_loss: 0.0671\n",
      "Epoch 59/60\n",
      "71/71 [==============================] - 25s 346ms/step - batch_loss: 0.0661\n",
      "Epoch 60/60\n",
      "71/71 [==============================] - 25s 347ms/step - batch_loss: 0.0662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd358767860>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_translator.fit(dataset, epochs=60,\n",
    "                     callbacks=[batch_loss, learning_rate_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "38rLdlmtQHCm",
    "outputId": "efbeff93-c194-42ce-e124-36a36f88c350"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'CE/token')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(batch_loss.logs)\n",
    "plt.ylim([0, 10])\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('CE/token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "iBQzFZ9uWU79"
   },
   "outputs": [],
   "source": [
    "translator = Translator(\n",
    "    encoder=train_translator.encoder,\n",
    "    decoder=train_translator.decoder,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyvxT5V0_X5B",
    "outputId": "039a2eea-9600-4df8-f83f-f89cba5f2f3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as encoder_2_layer_call_fn, encoder_2_layer_call_and_return_conditional_losses, decoder_2_layer_call_fn, decoder_2_layer_call_and_return_conditional_losses, embedding_4_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: portugues_trial_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: portugues_trial_6/assets\n"
     ]
    }
   ],
   "source": [
    "model_name = 'portugues_trial_6'\n",
    "tf.saved_model.save(translator, model_name,\n",
    "                    signatures={'serving_default': translator.tf_translate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-I0j3i3ekOba"
   },
   "outputs": [],
   "source": [
    "model_name = 'portugues_trial_6'\n",
    "reloaded = tf.saved_model.load(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXZF__FZXJCm",
    "outputId": "380eaf26-17ba-4dcd-8261-ed6e5da6e3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A notícia desta viagem causou grande espanto.\n",
      "a a noticia de desta vi viagem com fazer grande grande espanto\n",
      "------------\n",
      "A Zélia jogou e meteu um belo golo na baliza.\n",
      "a zelia a zelia jogou e meteu um belo golo na baliza\n",
      "------------\n",
      "A mãe do Flávio era florista.\n",
      "a mae do flavio era salada\n",
      "------------\n",
      "Vendia lindos gladíolos e glicínias.\n",
      "vendia lindos ge vendia lindos gladiolus e glicinias\n",
      "------------\n",
      "A Catarina e a Mira estão distraídas.\n",
      "a catarina e a mira estao distraidas\n",
      "------------\n",
      "Quero eu, quero eu! Sou muito comilão, mas também dizem que sou bonacheirão.\n",
      "quero eu quero eu sou muito comilao mas tambem dizem que sou la comilao mas tambem dizem que sou tudo la\n",
      "------------\n",
      "És muito simpático e pareces ser divertido.\n",
      "esta este esta muito e simpatico e pareces ser divertido\n",
      "------------\n",
      "Mas com essa voz, acordavas-me a mim e aos meninos de noite!\n",
      "mas com essa voz acurdavasme a mim e aos um meninos de noite\n",
      "------------\n",
      "Quase enraivecida, a cegonha largou a falar como uma matraca.\n",
      "ca co e um cegonha largou a falar com uma um matraca\n",
      "------------\n",
      "Ficaram a conversar na varanda.\n",
      "ficaram a conversar na varanda\n",
      "------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# seems to be much more stable now - I suspect it's overfitting - \n",
    "# prompts are repeated 2-14 times so need to build a better mini test set\n",
    "\n",
    "test_sentences = tf.constant(inputs[10:20])  # not used in training \n",
    "#test_sentences = tf.constant(inputs[20:30])  #targets[20:] is training\n",
    "\n",
    "result = reloaded.tf_translate(test_sentences)\n",
    "\n",
    "for orig, tr in zip(test_sentences, result['text']):\n",
    "    print(orig.numpy().decode())\n",
    "    print(tr.numpy().decode())\n",
    "    print(\"------------\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "nmt_with_attention.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
