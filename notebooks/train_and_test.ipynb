{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nparslow/disfluency_gen/blob/develop/docs/tutorials/nmt_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tnxXKDjq3jEL",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# refactored from:\n",
    "#https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/nmt_with_attention.ipynb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "repoRoot = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(os.path.join(repoRoot, \"src\", \"disfluency_generator\"))\n",
    "\n",
    "import tensorflow as tf\n",
    "from machine_translator import load_data, create_dataset, print_examples, tf_lower_and_split_punct,\\\n",
    "    create_text_processor\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from trainTranslator import TrainTranslator, BatchLogs\n",
    "from maskedLoss import MaskedLoss\n",
    "\n",
    "from translator import Translator\n",
    "from trainTranslator import TrainTranslator\n",
    "\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRVATYOgJs1b",
    "outputId": "0d4f0d79-6557-4c52-cb30-19c63d031a35",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last example of data:\n",
      "Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n",
      "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n",
      "tf.Tensor(\n",
      "[b'Se fue a la tienda en bicicleta.'\n",
      " b'Me acordar\\xc3\\xa9 de ti para siempre.'\n",
      " b'\\xc2\\xbfDe qui\\xc3\\xa9n esperas obtener regalos de Navidad?'\n",
      " b'\\xc2\\xbfVes lo que quiero decir?' b'T\\xc3\\xba no eres japon\\xc3\\xa9s.'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b'She took her bike to the store.' b\"I'll remember you forever.\"\n",
      " b'Who do you expect to receive Christmas presents from?'\n",
      " b'Do you see what I mean?' b'You are not Japanese.'], shape=(5,), dtype=string)\n",
      "First 10 words of input vocab:\n",
      "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']\n",
      "First 10 words of target vocab:\n",
      "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']\n",
      "Example input token sequences (indices):\n",
      "tf.Tensor(\n",
      "[[   2   17    5 3211    8  159    4    3    0    0]\n",
      " [   2   10 2356  139  352 4632    4    3    0    0]\n",
      " [   2    5   22  451  207   19   21   67    4    3]], shape=(3, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_path = pathlib.Path(\"/home/nickp/Documents/tutorials/disfluency_generator/data\")\n",
    "verbose = 1\n",
    "#------------------\n",
    "data_filename = pathlib.Path(data_path, \"spa-eng\", \"spa.txt\")\n",
    "\n",
    "targets, inputs = load_data(data_filename)\n",
    "\n",
    "if verbose > 0:\n",
    "    print(f\"Last example of data:\\n{inputs[-1]}\\n{targets[-1]}\")\n",
    "\n",
    "dataset = create_dataset(inputs, targets, BATCH_SIZE=64)\n",
    "\n",
    "if verbose > 0:\n",
    "    print_examples(dataset)\n",
    "\n",
    "# todo - check with corpus:\n",
    "max_vocab_size = 5000\n",
    "\n",
    "input_text_processor = create_text_processor(inputs, max_vocab_size)\n",
    "\n",
    "if verbose > 0:\n",
    "    # todo better checking:\n",
    "    print(\"First 10 words of input vocab:\")\n",
    "    print(input_text_processor.get_vocabulary()[:10])\n",
    "\n",
    "# note - we don't have to have the same output vocab size:\n",
    "output_text_processor = create_text_processor(targets, max_vocab_size)\n",
    "\n",
    "if verbose > 0:\n",
    "    print(\"First 10 words of target vocab:\")\n",
    "    print(output_text_processor.get_vocabulary()[:10])\n",
    "\n",
    "if verbose > 0:\n",
    "    for example_input_batch, example_target_batch in dataset.take(1):\n",
    "        print(\"Example input token sequences (indices):\")\n",
    "        example_tokens = input_text_processor(example_input_batch)\n",
    "        print(example_tokens[:3, :10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzQWx2saImMV"
   },
   "source": [
    "Before getting into it define a few constants for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_a9uNz3-IrF-"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aI02XFjoEt1k"
   },
   "source": [
    "Now that you're confident that the training step is working, build a fresh copy of the model to train from scratch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpObfY22IddU"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "While there's nothing wrong with writing your own custom training loop, implementing the `Model.train_step` method, as in the previous section, allows you to run `Model.fit` and avoid rewriting all that boiler-plate code. \n",
    "\n",
    "This tutorial only trains for a couple of epochs, so use a `callbacks.Callback` to collect the history of batch losses, for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J7m4mtnj80sq"
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_loss = BatchLogs('batch_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor)\n",
    "\n",
    "# Configure the loss and optimizer\n",
    "train_translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQd_esVVoSf3",
    "outputId": "2536bbf4-078b-4f12-b0ac-c3d59ef81dfc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_translator.fit(dataset, epochs=1,\n",
    "                     callbacks=[batch_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "38rLdlmtQHCm",
    "outputId": "efbeff93-c194-42ce-e124-36a36f88c350"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'CE/token')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(batch_loss.logs)\n",
    "plt.ylim([0, 3])\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('CE/token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iBQzFZ9uWU79"
   },
   "outputs": [],
   "source": [
    "translator = Translator(\n",
    "    encoder=train_translator.encoder,\n",
    "    decoder=train_translator.decoder,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyvxT5V0_X5B",
    "outputId": "039a2eea-9600-4df8-f83f-f89cba5f2f3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn, decoder_layer_call_and_return_conditional_losses, embedding_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translator/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translator/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(translator, 'translator',\n",
    "                    signatures={'serving_default': translator.tf_translate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-I0j3i3ekOba"
   },
   "outputs": [],
   "source": [
    "reloaded = tf.saved_model.load('translator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXZF__FZXJCm",
    "outputId": "380eaf26-17ba-4dcd-8261-ed6e5da6e3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "club york stands rats collected nowhere shoulders criticize colds describe bowed environment working someday flush abuse rare photo tidy chinese department teresa watermelon restaurant growth plate dictionary beach nervous memory just purchase sisters direction whining square bark homeless city medication died filled pigs burning overcome puppy punctual button technique scraps\n",
      "completed shoulder consideration interested growing separately fat pronounce apology economy rug cross exceptions showed marrying poverty airport spoiled neighborhood supper gang collection roll slightest reveal supplied card earthquake owns passengers betrayed fish refrigerator misled brakes consists seize several community cotton understand belt sympathy politician plays relative sailors ships slip champion\n",
      "nurse causing dealing tattoo dice coast build sons breath computer spell husbands daily conservative tomorrow shaving arrest too saves time potatoes beef slightly facebook comfortable rose risk visited messages indian origin spade feels pride broken shouted rushed nurse statement treating woods cheered mom technical insists survive economy symbol goodbye waited\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "three_input_text = tf.constant([\n",
    "    # This is my life.\n",
    "    'Esta es mi vida.',\n",
    "    # Are they still home?\n",
    "    '¿Todavía están en casa?',\n",
    "    # Try to find out.'\n",
    "    'Tratar de descubrir.',\n",
    "])\n",
    "\n",
    "result = reloaded.tf_translate(three_input_text)\n",
    "\n",
    "#%%time\n",
    "result = reloaded.tf_translate(three_input_text)\n",
    "\n",
    "for tr in result['text']:\n",
    "  print(tr.numpy().decode())\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "nmt_with_attention.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
